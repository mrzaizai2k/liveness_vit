notes: Increase weight decay
tags:
  - vit
  - large data

EPOCHS: 500
PATIENCE: 3
BATCH_SIZE: 32
learning_rate: 0.00003
IMG_SIZE: 224
MODEL_DIR: models/liveness/weights/vit_teacher_rm_unlabeled.pth
RANDOM_SEED: 39
NUM_CLASSES: 2
WEIGHT_DECAY: 0.5
LR_WARMUP: 10


train_dir: data/face_train
val_dir: data/face_val
test_dir: data/face_test

# [  6/500] Loss: 0.00000 | F1-score: 1.000 | Acc: 1.000 | Val Loss: 0.266 | Val F1: 0.860 | Val Acc: 0.929 | 00:40:56s | Grad: 0.00003
# EarlyStopping counter: 3 out of 3
# Early stopping after 6 Epochs
# test acc: 99.85585585585585%
# recall: 99.72997299729973%
# far: 0.06009615384615385%
# frr: 0.27002700270027%
# hter: 0.16506157827321194%

# Siw data base
# test acc: 96.25531914893617%
# recall: 92.4021040327294%
# far: 0.11025358324145534%
# frr: 7.597895967270602%
# hter: 3.8540747752560285%

# siw 16
# [  5/500] Loss: 0.01309 | F1-score: 0.997 | Acc: 0.998 | Val Loss: 0.453 | Val F1: 0.790 | Val Acc: 0.862 | 00:53:10s | Grad: 1.43401
# EarlyStopping counter: 3 out of 3
# Early stopping after 5 Epochs
# test acc: 99.63963963963964%
# recall: 99.09990999099911%
# far: 0.0%
# frr: 0.9000900090009001%
# hter: 0.45004500450045004%

# vit 19 epoch
# EarlyStopping counter: 30 out of 30
# Early stopping after 39 Epochs
# test acc: 88.46846846846846%
# recall: 71.1971197119712%
# far: 0.0%
# frr: 28.802880288028803%
# hter: 14.401440144014401%

# zalo data
# [ 11/500] Loss: 0.02798 | F1-score: 0.990 | Acc: 0.991 | Val Loss: 0.252 | Val F1: 0.845 | Val Acc: 0.943 | 04:21:27s | Grad: 2.62391
# EarlyStopping counter: 10 out of 10
# Early stopping after 11 Epochs
# test acc: 95.31279178338002%
# recall: 93.43096234309624%
# far: 3.170320404721754%
# frr: 6.569037656903766%
# hter: 4.86967903081276%


# zalo light config
# [ 11/500] Loss: 0.02454 | F1-score: 0.993 | Acc: 0.993 | Val Loss: 0.378 | Val F1: 0.863 | Val Acc: 0.923 | 04:14:42s | Grad: 2.69495
# EarlyStopping counter: 10 out of 10
# Early stopping after 11 Epochs
# test acc: 96.937441643324%
# recall: 96.86192468619247%
# far: 3.0016863406408096%
# frr: 3.1380753138075312%
# hter: 3.0698808272241704%